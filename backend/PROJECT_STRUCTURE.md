# Project Structure

```
mental-health-api/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                      # Main FastAPI application
â”‚   â”œâ”€â”€ Endpoints:
â”‚   â”‚   â”œâ”€â”€ GET  /                  # API info
â”‚   â”‚   â”œâ”€â”€ GET  /health            # Health check
â”‚   â”‚   â”œâ”€â”€ GET  /models            # Models information
â”‚   â”‚   â”œâ”€â”€ POST /analyze/text      # Text analysis
â”‚   â”‚   â”œâ”€â”€ POST /analyze/audio     # Audio analysis
â”‚   â”‚   â”œâ”€â”€ POST /analyze/video     # Video analysis
â”‚   â”‚   â””â”€â”€ POST /analyze/combined  # Combined analysis
â”‚   â”‚
â”‚   â””â”€â”€ Functions:
â”‚       â”œâ”€â”€ startup_event()         # Initialize all analyzers
â”‚       â”œâ”€â”€ shutdown_event()        # Cleanup resources
â”‚       â”œâ”€â”€ analyze_text()          # Text endpoint handler
â”‚       â”œâ”€â”€ analyze_audio()         # Audio endpoint handler
â”‚       â”œâ”€â”€ analyze_video()         # Video endpoint handler
â”‚       â”œâ”€â”€ analyze_combined()      # Combined endpoint handler
â”‚       â””â”€â”€ Helper functions...
â”‚
â”œâ”€â”€ ğŸ“„ text_analyzer.py             # Text Sentiment Analysis Module
â”‚   â”œâ”€â”€ Class: TextSentimentAnalyzer
â”‚   â”‚   â”œâ”€â”€ __init__()              # Initialize HF models
â”‚   â”‚   â”œâ”€â”€ analyze_sentiment_with_hf()   # HF API call
â”‚   â”‚   â”œâ”€â”€ generate_recommendations_with_hf()  # AI recommendations
â”‚   â”‚   â”œâ”€â”€ detect_risk_keywords()  # Keyword detection
â”‚   â”‚   â”œâ”€â”€ detect_emotions()       # Emotion detection
â”‚   â”‚   â””â”€â”€ analyze_text()          # Main analysis method
â”‚   â”‚
â”‚   â”œâ”€â”€ Models Used:
â”‚   â”‚   â”œâ”€â”€ tabularisai/multilingual-sentiment-analysis
â”‚   â”‚   â””â”€â”€ meta-llama/Llama-3.1-8B-Instruct:novita
â”‚   â”‚
â”‚   â””â”€â”€ Pydantic Models:
â”‚       â”œâ”€â”€ TextAnalysisRequest
â”‚       â”œâ”€â”€ TextAnalysisResponse
â”‚       â””â”€â”€ MentalHealthResources
â”‚
â”œâ”€â”€ ğŸ“„ audio_analyzer.py            # Audio Emotion Analysis Module
â”‚   â”œâ”€â”€ Class: AudioEmotionAnalyzer
â”‚   â”‚   â”œâ”€â”€ __init__()              # Initialize audio models
â”‚   â”‚   â”œâ”€â”€ analyze_emotion()       # Main emotion analysis
â”‚   â”‚   â”œâ”€â”€ _fallback_emotion_analysis()  # Fallback method
â”‚   â”‚   â”œâ”€â”€ calculate_risk_score()  # Risk calculation
â”‚   â”‚   â”œâ”€â”€ get_recommendations()   # Get recommendations
â”‚   â”‚   â””â”€â”€ analyze_audio_file()    # Main analysis method
â”‚   â”‚
â”‚   â”œâ”€â”€ Class: AudioProcessor
â”‚   â”‚   â”œâ”€â”€ convert_to_wav()        # Format conversion
â”‚   â”‚   â”œâ”€â”€ load_audio()            # Load audio data
â”‚   â”‚   â””â”€â”€ validate_audio()        # Validation
â”‚   â”‚
â”‚   â””â”€â”€ Models Used:
â”‚       â””â”€â”€ firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3
â”‚
â”œâ”€â”€ ğŸ“„ video_analyzer.py            # Video Emotion Detection Module
â”‚   â”œâ”€â”€ Class: VideoEmotionDetector
â”‚   â”‚   â”œâ”€â”€ __init__()              # Initialize video models
â”‚   â”‚   â”œâ”€â”€ _detect_emotion_hf()    # HF emotion detection
â”‚   â”‚   â”œâ”€â”€ _approximate_emotion_from_landmarks()  # Fallback
â”‚   â”‚   â”œâ”€â”€ _detect_face_orientation()  # Face tracking
â”‚   â”‚   â”œâ”€â”€ process_video()         # Main video processing
â”‚   â”‚   â”œâ”€â”€ _generate_summary()     # Generate summary
â”‚   â”‚   â””â”€â”€ cleanup()               # Resource cleanup
â”‚   â”‚
â”‚   â””â”€â”€ Models Used:
â”‚       â”œâ”€â”€ dima806/facial_emotions_image_detection
â”‚       â””â”€â”€ MediaPipe Face Detection + Face Mesh
â”‚
â”œâ”€â”€ ğŸ“„ gemini_integrator.py         # Google Gemini AI Integration
â”‚   â”œâ”€â”€ Class: GeminiIntegrator
â”‚   â”‚   â”œâ”€â”€ __init__()              # Initialize Gemini API
â”‚   â”‚   â”œâ”€â”€ generate_recommendations()  # Main generation
â”‚   â”‚   â”œâ”€â”€ _build_context()        # Context builder
â”‚   â”‚   â”œâ”€â”€ _parse_text_response()  # Response parser
â”‚   â”‚   â”œâ”€â”€ _get_fallback_response()  # Fallback
â”‚   â”‚   â””â”€â”€ test_connection()       # Connection test
â”‚   â”‚
â”‚   â””â”€â”€ API Used:
â”‚       â””â”€â”€ Google Gemini Pro API
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python Dependencies
â”‚   â”œâ”€â”€ FastAPI & Uvicorn           # Web framework
â”‚   â”œâ”€â”€ Transformers & HuggingFace  # AI models
â”‚   â”œâ”€â”€ Librosa & Soundfile         # Audio processing
â”‚   â”œâ”€â”€ OpenCV & MediaPipe          # Video processing
â”‚   â”œâ”€â”€ Google Generative AI        # Gemini API
â”‚   â””â”€â”€ Supporting libraries...
â”‚
â”œâ”€â”€ ğŸ“„ .env.example                 # Environment Variables Template
â”‚   â”œâ”€â”€ HF_TOKEN                    # Hugging Face API token
â”‚   â”œâ”€â”€ GEMINI_API_KEY              # Google Gemini API key
â”‚   â””â”€â”€ Configuration settings...
â”‚
â”œâ”€â”€ ğŸ“„ .env                         # Your Actual Environment Variables
â”‚   â””â”€â”€ (Create this from .env.example)
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Main Documentation
â”‚   â”œâ”€â”€ Features overview
â”‚   â”œâ”€â”€ Installation guide
â”‚   â”œâ”€â”€ Usage examples
â”‚   â”œâ”€â”€ API endpoints
â”‚   â””â”€â”€ Troubleshooting
â”‚
â”œâ”€â”€ ğŸ“„ SETUP.md                     # Detailed Setup Guide
â”‚   â”œâ”€â”€ Step-by-step installation
â”‚   â”œâ”€â”€ System dependencies
â”‚   â”œâ”€â”€ Common issues
â”‚   â””â”€â”€ Production deployment
â”‚
â”œâ”€â”€ ğŸ“„ test_api.py                  # Comprehensive Test Suite
â”‚   â”œâ”€â”€ test_api_health()           # Health check test
â”‚   â”œâ”€â”€ test_models_info()          # Models info test
â”‚   â”œâ”€â”€ test_text_analysis()        # Text analysis tests
â”‚   â”œâ”€â”€ test_audio_analysis()       # Audio analysis tests
â”‚   â”œâ”€â”€ test_video_analysis()       # Video analysis tests
â”‚   â””â”€â”€ test_combined_analysis()    # Combined analysis tests
â”‚
â”œâ”€â”€ ğŸ“ tests/ (optional)            # Additional Test Files
â”‚   â”œâ”€â”€ test_text.py
â”‚   â”œâ”€â”€ test_audio.py
â”‚   â””â”€â”€ test_video.py
â”‚
â””â”€â”€ ğŸ“ venv/                        # Virtual Environment (created during setup)
    â””â”€â”€ (Python packages installed here)
```

## Module Dependencies

```
main.py
 â”œâ”€â”€ text_analyzer.py
 â”‚    â””â”€â”€ Hugging Face API
 â”‚         â”œâ”€â”€ tabularisai/multilingual-sentiment-analysis
 â”‚         â””â”€â”€ meta-llama/Llama-3.1-8B-Instruct:novita
 â”‚
 â”œâ”€â”€ audio_analyzer.py
 â”‚    â””â”€â”€ Hugging Face API
 â”‚         â””â”€â”€ firdhokk/speech-emotion-recognition-with-openai-whisper-large-v3
 â”‚
 â”œâ”€â”€ video_analyzer.py
 â”‚    â””â”€â”€ Hugging Face + MediaPipe
 â”‚         â”œâ”€â”€ dima806/facial_emotions_image_detection
 â”‚         â””â”€â”€ MediaPipe Face Detection/Mesh
 â”‚
 â””â”€â”€ gemini_integrator.py
      â””â”€â”€ Google Gemini API
           â””â”€â”€ gemini-pro model
```

## Data Flow

```
1. TEXT ANALYSIS FLOW:
   User Input (text)
        â†“
   TextSentimentAnalyzer
        â†“
   HF Sentiment Model â†’ Emotion Detection â†’ Risk Calculation
        â†“
   HF LLM Model â†’ Generate Recommendations
        â†“
   Return: Risk Level, Emotions, Recommendations

2. AUDIO ANALYSIS FLOW:
   User Input (audio file)
        â†“
   AudioProcessor (convert/validate)
        â†“
   AudioEmotionAnalyzer
        â†“
   HF Audio Model â†’ Emotion Scores â†’ Risk Calculation
        â†“
   Return: Primary Emotion, Risk Level, Recommendations

3. VIDEO ANALYSIS FLOW:
   User Input (video file)
        â†“
   VideoEmotionDetector
        â†“
   MediaPipe Face Detection â†’ Extract Faces
        â†“
   HF Emotion Model â†’ Emotion per Frame
        â†“
   Aggregate Results â†’ Emotion Timeline
        â†“
   Return: Emotion Distribution, Stability, Summary

4. COMBINED ANALYSIS FLOW:
   User Input (text + audio + video)
        â†“
   Parallel Analysis:
        â”œâ”€â”€ Text Analysis (TextSentimentAnalyzer)
        â”œâ”€â”€ Audio Analysis (AudioEmotionAnalyzer)
        â””â”€â”€ Video Analysis (VideoEmotionDetector)
        â†“
   Aggregate Results:
        â”œâ”€â”€ Calculate average risk score
        â”œâ”€â”€ Combine all detected emotions
        â””â”€â”€ Determine overall risk level
        â†“
   GeminiIntegrator
        â”œâ”€â”€ Build comprehensive context
        â”œâ”€â”€ Generate personalized recommendations
        â””â”€â”€ Create tailored advice
        â†“
   Return: Combined Analysis + AI Recommendations
```

## API Response Structure

```
COMBINED ANALYSIS RESPONSE:
{
  "overall_risk_level": "MEDIUM",
  "overall_risk_score": 42.5,
  "overall_confidence": 0.78,
  
  "text_analysis": {
    "risk_level": "MEDIUM",
    "risk_score": 45.0,
    "detected_emotions": ["anxiety", "stress"],
    "recommendations": [...]
  },
  
  "audio_analysis": {
    "risk_level": "MEDIUM",
    "primary_emotion": "sad",
    "emotion_scores": {...},
    "recommendations": [...]
  },
  
  "video_analysis": {
    "status": "success",
    "summary": {
      "most_frequent_emotion": "sadness",
      "emotion_distribution": {...},
      "emotional_stability": 0.65
    }
  },
  
  "combined_emotions": ["anxiety", "sadness", "stress", "fear"],
  
  "ai_recommendations": [
    "Personalized recommendation 1 from Gemini",
    "Personalized recommendation 2 from Gemini",
    "Personalized recommendation 3 from Gemini"
  ],
  
  "personalized_advice": "Detailed compassionate advice from Gemini AI...",
  
  "next_steps": [
    "Actionable step 1",
    "Actionable step 2",
    "Actionable step 3"
  ],
  
  "emergency_resources": {
    "Vandrevala Foundation": "9999666555",
    ...
  },
  
  "models_used": {
    "text": "tabularisai/multilingual-sentiment-analysis",
    "audio": "firdhokk/speech-emotion-recognition...",
    "video": "dima806/facial_emotions_image_detection"
  }
}
```

## Key Features by Module

### text_analyzer.py
- âœ… Multi-language sentiment analysis
- âœ… Risk keyword detection (CRITICAL, HIGH, MEDIUM, LOW)
- âœ… Emotion detection from text
- âœ… AI-powered recommendations using LLM
- âœ… Mental health resources database
- âœ… Confidence scoring

### audio_analyzer.py
- âœ… Multiple audio format support (wav, mp3, m4a, flac, ogg)
- âœ… Emotion recognition from speech
- âœ… Audio feature extraction (MFCC, spectral, etc.)
- âœ… Fallback analysis when API unavailable
- âœ… Risk calculation from audio emotions
- âœ… Duration validation

### video_analyzer.py
- âœ… Real-time facial emotion detection
- âœ… Frame-by-frame analysis with skip optimization
- âœ… Emotion timeline tracking
- âœ… Emotional stability calculation
- âœ… Multiple face support
- âœ… Face orientation detection
- âœ… Comprehensive summary statistics

### gemini_integrator.py
- âœ… Context-aware recommendation generation
- âœ… Personalized advice based on all inputs
- âœ… Risk-appropriate guidance
- âœ… Fallback responses when API unavailable
- âœ… JSON response parsing
- âœ… Compassionate communication style

### main.py
- âœ… Unified API interface
- âœ… CORS configuration
- âœ… Comprehensive error handling
- âœ… Health monitoring
- âœ… Interactive documentation (Swagger UI)
- âœ… Async support for concurrent requests
- âœ… File upload handling
- âœ… Session tracking
